---
title: "**OptiClust: Improved method for assigning amplicon-based sequence data to operational taxonomic units**"
bibliography: references.bib
output:
  pdf_document:
    includes:
      in_header: header.tex
csl: msystems.csl
fontsize: 11pt
geometry: margin=1.0in
---


```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
library(dplyr, warn.conflicts=FALSE)
library(tidyr)
library(knitr)

opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x){
	print(x)
	if(is.numeric(x)){
		if(abs(x - round(x)) < .Machine$double.eps^0.5){
			paste(format(x,big.mark=',', digits=0, scientific=FALSE))
		} else {
			paste(format(x,big.mark=',', digits=2, nsmall=2, scientific=FALSE))
		}

	} else {
    	paste(x)      
	}
}
knitr::knit_hooks$set(inline=inline_hook)

basic_methods <- c('an', 'fn', 'nn', 'otuclust', 'sumaclust', 'swarm',
										'uagc', 'udgc', 'vagc_1', 'vdgc_1', 'mcc')

```

\begin{center}
\vspace{25mm}
Sarah L. Westcott and Patrick D. Schloss${^\dagger}$

\vspace{30mm}

$\dagger$ To whom correspondence should be addressed: pschloss@umich.edu

Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
\end{center}


\newpage
\linenumbers

## Abstract



\newpage

## Introduction

Amplicon-based sequencing has provided incredible insights into Earth's microbial biodiversity.

Numerous methods have been proposed

Needed an objective criteria to evaluate the various methods methods

Average neighbor is consistently the best method, but others including USEARCH and VSEARCH resulted in comparable results

Difficulty with amount of memory and time required to complete average neighbor algorithm is a significant hurdle to completion of the method.

Instead of retrospectively evaluating methods for their ability to correctly assign sequences we sought to develop a method that would prospectively assign sequences to OTUs to optimize classification metrics.

Clustering quality within the algorithm is assessed by counting the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) based on the pairwise distances. Sequence pairs that are within the user-specified threshold and are clustered together represent TPs and those in different OTUs are FNs. Those sequence pairs that have a distance larger than the threshold and are not clustered in the same OTU are TNs and those in the same OTU are FPs. These counts are used to calculate the optimization metric.

***Optimization of clustering using composite metrics significantly improves clustering quality (Figure 2, 3, 4).*** There are multiple metrics available to assess clustering quality. The mothur-based implementation of OptiClust allows the user to use the MCC, F1 score, accuracy, sensitivity, specificity, and the sum of true positives and negatives. The MCC, F1 score, and accuracy are preferred because each of them incorporates all four values from the confusion matrix while others only utilize two values. It is relatively straightforward to implement other metrics. **Comparison of MCC, accuracy, and F1 score to each other for each dataset using the full set of sequences.** Each metric outperformed the observed values for the other clustering algorithms indicating that regardless of the metric one uses to evaluate clustering quality, the OptiClust algorithm generates better OTU assignments than any of the other methods. The number of OTUs generated by an algorithm is often used as a metric for clustering quality. We did not observe a significant correlation between clustering quality as measured by MCC, F1 score, or accuracy and the number of OTUs generated by each algorithm. **Interestingly, the values of the MCC, F1 score, and accuracy generated when using each metric to optimize clustering were similar across implementations.** Based on these results and its previous use in the OTU assignment literature, the remainder of our analysis uses the MCC metric for optimization.


## Results


***OptiClust algorithm.***

The OptiClust algorithm uses the metric that should be used to assess clustering quality, a list of all sequence names in the dataset, and the pairs of sequences that are within a desired threshold of each other (e.g. 0.03). A detailed description of the algorithm is provided for a toy dataset in the Supplementary Material. Briefly, the algorithm starts by placing each sequence either within its own OTU or into a single OTU. The algorithm proceeds by interrogating each sequence and re-calculating the metric for the cases where the sequence stays in its current OTU, is moved to each of the other OTUs, or is moved into a new OTU. The location that results in the best clustering quality indicates whether the sequence should remain in its current OTU or be moved to a different or new OTU. Each iteration consists of interrogating every sequence in the dataset. Although numerous options are available within the mothur-based implementation of the algorithm (e.g. sensitivity, specificity, accuracy, F1 score, etc.), the default metric is MCC because it includes all four parameters from the confusion matrix. The algorithm continues until the optimization metric stabilizes or until it reaches a defined stopping criteria.


***OptiClust-generated OTUs are more robust than those from other methods.***

```{r performance_analysis}
perf <- read.table(file="data/processed/cluster_data.summary", header=T) %>%
				filter(frac == 1.0, method %in% basic_methods) %>%
				select(dataset, method, cluster_secs, cluster_kb, mcc, num_otus) %>%
				group_by(dataset, method) %>%
				summarize(
					mean_secs = mean(cluster_secs, na.rm=T),
					mean_kb = mean(cluster_kb, na.rm=T),
					mean_mcc = mean(mcc, na.rm=T),
					mean_num_otus = mean(num_otus, na.rm=T)
				)
perf_summary <- perf %>%
				group_by(method) %>%
				summarize(
					mean_mcc = mean(mean_mcc, na.rm=T),
					mean_secs = mean(mean_secs, na.rm=T)
				) %>%
				mutate(
					rel_mcc = mean_mcc/mean_mcc[method=='mcc'],
					rel_secs = mean_secs/mean_secs[method=='mcc']
				)

mcc_rel_an <-100*(1-perf_summary %>% filter(method=="an") %>% select(rel_mcc))
mcc_rel_vdgc <- 100*(1-perf_summary %>% filter(method=="vdgc_1") %>% select(rel_mcc))

secs_rel_an <- perf_summary %>% filter(method=="an") %>% select(rel_secs)
secs_rel_vdgc <- perf_summary %>% filter(method=="vdgc_1") %>% select(rel_secs)

mcc_sobs_cor <- cor.test(perf$mean_num_otus, perf$mean_mcc, method="spearman")
```

To evaluate the OptiClust algorithm and compare its performance to other algorithms, we utilized six datasets including two synthetic communities and four previously published large datasets generated from soil, marine, human, and murine samples (Table 1). When we seeded the OptiClust algorithm with each sequence in a separate OTU and ran the algorithm until complete convergence, the MCC values were `r round(mcc_rel_an, 1)` and `r round(mcc_rel_vdgc, 1)`% higher than the OTUs using average neighbor and distance-based greedy clustering (DGC) with VSEARCH, respectively (Figure 1). The number of OTUs formed by the various methods was negatively correlated with their MCC value ($\rho$=`r round(mcc_sobs_cor$estimate, 2)`; p=`r round(mcc_sobs_cor$p.value, 2)`). The OptiClust algorithm was considerably faster than the hierarchical algorithms and somewhat slower than the heuristic-based algorithms. Across the six datasets, the OptiClust algorithm was `r round(secs_rel_an, 1)`-times faster than average neighbor and `r round(1/secs_rel_vdgc, 1)`-times slower than DGC with VSEARCH. The human dataset was a challenge for a number of the algorithms. OTUCLUST and SumaClust were unable to cluster the human dataset in less than 50 hours and the average neighbor algorithm required more than 45 GB of RAM. The USEARCH-based methods were unable to cluster the human data using the 32-bit free version of the software that limits the amount of RAM to approximately 3.5 GB. These data demonstrate that OptiClust generates significantly more robust OTU assignments than existing methods across a diverse collection of datasets with performance that is comparable to popular methods.


***OptiClust stopping criteria.***

```{r stopping_analysis}
steps <- read.table(file="data/processed/mcc_steps.summary", header=T) %>%
					filter(frac == 1.0, dataset!="even", dataset!="staggered") %>%
					select(-rep, -frac, -method, -contains("_secs_cluster")) %>%
					group_by(dataset) %>%
					summarize(med_full_secs = median(full_secs),
							per_diff_mcc = 100 * mean((full_mcc-close_mcc)/full_mcc),
							diff_numotus = median(close_num_otus - full_num_otus),
							per_diff_numotus = 100 * mean((close_num_otus - full_num_otus)/full_num_otus),
							ratio_secs = mean(full_secs/close_secs),
							med_close_steps = median(close_steps),
							med_full_steps = median(full_steps)
					)
```

By default, the mothur-based implementation of the algorithm stops when the optimization metric changes by less than 0.0001; however, this can be altered by the user. This implementation also allows the user to stop the algorithm if a maximum number of iterations is exceeded. By default mothur uses a maximum value of 100 iterations. The justification for allowing incomplete convergence was based on the observation that numerous iterations are performed that extend the time required to complete the clustering with minimal improvement in clustering. We evaluated the results of clustering to partial convergence (i.e. a change in the MCC value that was less than 0.0001) or until complete convergence of the MCC value (i.e. until it did not change between iterations) when seeding the algorithm with each sequence in a separate OTU (Figure 1). The small difference in MCC values between the output from partial and complete convergence resulted in a difference in the median number of OTUs that ranged between `r paste(format(round(range(steps$diff_numotus), 1), nsmall=1L), collapse=" and ")` OTUs. This represented a difference of less than `r format(round(max(steps$per_diff_numotus), 2), nsmall=1L)`%. Among the four natural datasets, between `r min(steps$med_close_steps)` and `r max(steps$med_close_steps)` were needed to achieve partial convergence and between `r min(steps$med_full_steps)` and `r max(steps$med_full_steps)` iterations were needed to reach full convergence. The additional steps required between `r paste(format(round(range(steps$ratio_secs), 1), nsmall=1L), collapse=" and ")` times longer to complete the algorithm. These results suggest that achieving full convergence of the optimization metric adds computational effort; however, considering full convergence took between `r paste(round(range(steps$med_full_secs/60), 0), collapse=" and ")` minutes the extra effort was relatively small. Although the mothur's default setting is partial convergence, the remainder of our analysis used complete convergence to be more conservative.


***Effect of seeding OTUs on OptiClust performance.***

```{r aggregate_analysis}
agg <- read.table(file="data/processed/cluster_data.summary", header=T) %>%
			filter(frac==1.0, method %in% (c("mcc", "mcc_agg"))) %>%
			select(dataset, method, cluster_secs, mcc, num_otus) %>%
			group_by(dataset, method) %>%
			summarize(
				mean_secs = mean(cluster_secs, na.rm=T),
				mean_mcc = mean(mcc, na.rm=T),
				mean_num_otus = mean(num_otus, na.rm=T)
			) %>%
			group_by(dataset) %>%
			summarize(
				fold_secs = mean_secs[method=="mcc_agg"]/mean_secs[method=="mcc"],
				per_diff_mcc = 100*(1-mean_mcc[method=="mcc_agg"]/mean_mcc[method=="mcc"]),
				per_diff_num_otus =100*(1-mean_num_otus[method=="mcc_agg"]/mean_num_otus[method=="mcc"])
			)
```

As implemented within mothur, the OptiClust algorithm either starts with each sequence in a separate OTU or with all of the sequences in a single OTU. We repeated the complete convergence analysis, but seeded the algorithm with all sequences in a single OTU. We found that the MCC values for clusters generated seeding OptiClust with the sequences as a single OTU were between `r paste(round(range(agg$per_diff_mcc), 1), collapse=" and ")`% lower than when seeding the algorithm with sequences in separate OTUs (Figure 1). Interestingly, with the exception of the `r agg[which.min(agg$per_diff_num_otus),"dataset"]` dataset (`r format(abs(round(agg[which.min(agg$per_diff_num_otus),"per_diff_num_otus"], 1)), nsmall=1L)`% more OTUs), the number of OTUs was as much as `r format(round(agg[which.max(agg$per_diff_num_otus),"per_diff_num_otus"], 1), nsmall=1L)`% lower (`r agg[which.max(agg$per_diff_num_otus),"dataset"]`) than when the algorithm was seeded with sequence in separate OTUs. Finally, the amount of time required to cluster the data when the algorithm was seeded with a single OTU was between `r paste(format(round(range(agg$fold_secs), 1), nsmall=1L), collapse=" and ")`-times longer than if sequences were seeded as separate OTUs. This analysis demonstrates that seeding the algorithm with sequences as separate OTUs results in the best OTU assignments in the shortest amount of time.


***OptiClust-generated OTUs are as stable as those from other algorithms.***

```{r stability_analysis}
stability <- read.table(file="data/processed/cluster_data.summary",header=T) %>%
						filter(frac == 1.0, method %in% basic_methods) %>%
						select(dataset, method, mcc, num_otus) %>%
						group_by(dataset, method) %>%
						summarize(
							cov_mcc = sd(mcc) / mean(mcc) * 100,
							cov_num_otus = sd(num_otus) / mean(num_otus) * 100
						) %>%
						group_by(method) %>%
						summarize(
							med_cov_mcc = median(cov_mcc, na.rm=T),
							med_cov_num_otus = median(cov_num_otus, na.rm=T)
						)
```

One concern that many have with *de novo* clustering algorithms is that their output is sensitive to the initial order of the sequences. An additional concern with the OptiClust algorithm is that it may stabilize at a local optimum. To evaluate these concerns we compared the results obtained using ten randomizations of the order that sequences were given to the algorithm. The median the coefficient of variation across the six datasets for MCC values obtained from the replicate clusterings using OptiClust was `r format(round(stability %>% filter(method=="mcc") %>% select(med_cov_mcc), 1), nsmall=1L)`% (Figure 1). We also measured the coefficient of variation for the number of OTUs across the six datasets for each method. The median coefficient of variation for the number of OTUs generated using OptiClust was `r format(round(stability %>% filter(method=="mcc") %>% select(med_cov_num_otus), 1), nsmall=1L)`%. Confirming our previous results, all of the methods we tested were stable to stochastic processes. Of the method that involved randomization, the coefficient of variation for MCC values considerably smaller than the other methods and the coefficient of variation for the number of OTUs was comparable to the other methods. The variation observed in clustering quality suggests that the algorithm does not appear to converge to a locally optimum MCC value. More importantly, the random variation does yield output of a similarly high quality.


***Time and memory required to complete Optimization-based clustering scales efficiently.***

```{r scaling_analysis}
datasets <- c('human', 'mice', 'marine', 'soil')

speed_data <- read.table(file="data/processed/mcc_steps.summary", header=T)

speed_models <- speed_data %>%
		filter(dataset %in% datasets) %>%
		select(dataset, frac, full_secs_cluster, full_steps) %>%
		group_by(dataset) %>%
		do(
			model = nls((full_secs_cluster/full_steps) ~ b * frac ^ z,
														start = list(b = 1000, z = 2), data= .)
		)

speed_coef <- c(
		speed_models[speed_models$dataset=="human",2][[1]][[1]]$m$getPars()["z"],
		speed_models[speed_models$dataset=="mice",2][[1]][[1]]$m$getPars()["z"],
		speed_models[speed_models$dataset=="marine",2][[1]][[1]]$m$getPars()["z"],
		speed_models[speed_models$dataset=="soil",2][[1]][[1]]$m$getPars()["z"]
	)
names(speed_coef) <- datasets

memory_data <- read.table(file="data/processed/cluster_data.summary", header=T)

memory_models <- memory_data %>%
		filter(dataset %in% datasets, method == "mcc") %>%
		mutate(cluster_gb=cluster_kb/1048000) %>%
		select(dataset, frac, cluster_gb) %>%
		group_by(dataset) %>%
		do(model = nls((cluster_gb) ~ b * frac ^ z, start = list(b = 1e6, z = 3), data= .))

memory_coef <- c(
		memory_models[memory_models$dataset=="human",2][[1]][[1]]$m$getPars()["z"],
		memory_models[memory_models$dataset=="mice",2][[1]][[1]]$m$getPars()["z"],
		memory_models[memory_models$dataset=="marine",2][[1]][[1]]$m$getPars()["z"],
		memory_models[memory_models$dataset=="soil",2][[1]][[1]]$m$getPars()["z"]
	)
names(memory_coef) <- datasets

```

Although not as important as the quality of clustering, the amount of time and memory required to assign sequences to OTUs is a legitimate concern. To evaluate how the speed and memory usage scaled with the number of sequences in the dataset, we measured the time required and maximum RAM usage to cluster 20, 40, 60, 80, and 100% of the unique sequences from each of the natural datasets using the OptiClust algorithm (Figure 2). Within each iteration of the algorithm, each sequence is compared to every other sequence and each comparison requires a recalculation of the confusion matrix. This would result in a worst case algorithmic complexity on the order of N^3, where N is the number of unique sequences. Because the algorithm only needs to keep track of the sequence pairs that are within the threshold of each other, it is likely that the implementation of the algorithm is more efficient. To empirically determine the algorithmic complexity, we fit a power law function to the data in Figure 2A. We observed power coefficients between `r paste(format(round(range(speed_coef), 1), nsmall=1L), collapse=" and ")` for the `r paste(names(speed_coef[c(which.min(speed_coef), which.max(speed_coef))]), collapse=" and ")` datasets, respectively. The algorithm requires storing a matrix that contains the pairs of sequences that are close to each other as well as a matrix that indicates which sequences are clustered together. The memory required to store these matrices is on the order of N^2, where N is the number of unique sequences. In fact, when we fit a power law function to the data in Figure 2B, the power coefficients were  `r format(round(median(memory_coef), 1), nsmall=1L)`. This analysis suggests that doubling the number of sequences in a dataset would increase the time required to cluster the data by 4 to 8-fold and increase the RAM required by 4-fold. It is possible that future improvements to the implementation of the algorithm could improve this performance.


```{r split_analysis}
datasets <- c('soil', 'marine', 'mice', 'human')

full_data <- read.table(file="data/processed/cluster_data.summary", header=T, stringsAsFactors=FALSE)

full_data$method <- gsub("^mcc$", "mcc_split1_8", full_data$method)
full_data$method <- gsub("^vdgc_1$", "vdgc_split1_8", full_data$method)
full_data$method <- gsub("^an$", "an_split1_8", full_data$method)

split_data <- full_data %>%
				mutate(method = gsub("^mcc$", "mcc_split1_8", method)) %>%
				mutate(method = gsub("^vdgc_1$", "vdgc_split1_8", method)) %>%
				mutate(method = gsub("^an$", "an_split1_8", method)) %>%
				filter(
						grepl("split", method),
						frac==1.0,
						dataset==datasets
				) %>%
				select(dataset, method, mcc, num_otus) %>%
				separate(method, into=c("method", "split", "processors"), sep="_") %>%
				mutate(tax_level=as.numeric(gsub("split", "", split))) %>%
				select(-split, -processors) %>%
				gather(metric, value, mcc, num_otus) %>%
				group_by(dataset, method, metric, tax_level) %>%
				summarize(
					mean=if(sum(!is.na(value))>0){mean(value, na.rm=TRUE)}	else { NA }
				)

rel_mcc_data <- split_data %>%
			filter(metric == "mcc") %>%
			group_by(dataset, method, tax_level) %>%
			summarize(mean = mean(mean, na.rm=T)) %>%
			group_by(dataset, method) %>%
			mutate(rel_mean=mean/mean[tax_level==1]) %>%
			group_by(method, tax_level) %>%
			summarize(min_mcc = min(rel_mean, na.rm=T))

rel_otu_data <- split_data %>%
			filter(metric == "num_otus") %>%
			group_by(dataset, method, tax_level) %>%
			summarize(mean = mean(mean, na.rm=T)) %>%
			group_by(dataset, method) %>%
			mutate(rel_mean=mean/mean[tax_level==1]) %>%
			group_by(method, tax_level) %>%
			summarize(max_num_otus = max(rel_mean, na.rm=T))

```

***Cluster splitting heuristic generates OTUs that are as good as non-split approach (Figure 6).***

We previously described a heuristic to accelerate OTU assignments where sequences were classified to taxonomic groups and within each taxon sequences were assigned to OTUs using the average neighbor clustering algorithm. This can accelerate the clustering and reduce the memory requirements because the number of unique sequences is effectively reduced by splitting sequences across taxonomic groups. Furthermore, because sequences in different taxonomic groups are assumed to belong to different OTUs they are independent, which permits parallelization and additional reduction in computation time. Reduction in clustering quality are encountered in this approach if there are errors in classification or if two sequences within the desired threshold belong to different taxonomic groups. It is expected that these errors would increase as the taxonomic level goes from kingdom to genus. To characterize the clustering quality, we calculated the MCC values using OptiClust, average neighbor, and DGC with VSEARCH when splitting at each taxonomic level (Figure 3). For each method, the MCC values decreased as the taxonomic resolution increased; however, the decrease in MCC as not as large as the difference between clustering methods. As the resolution of the taxonomic levels increased, the clustering quality remained high, relative to clusters formed from the entire dataset (i.e. kingdom-level). The MCC values when splitting the datasets at the class and genus levels were within `r format(round(min(100*(rel_mcc_data %>% filter(tax_level == 3))$min_mcc), 1), nsmall=1L)` and `r format(round(min(100*(rel_mcc_data %>% filter(tax_level == 6))$min_mcc), 1), nsmall=1L)`%, respectively, of the MCC values obtained from the entire dataset. These decreases in MCC value resulted in the formation of as many as `r format(round(min(100*((rel_otu_data %>% filter(tax_level == 3))$max_num_otus-1), na.rm=T), 1), nsmall=1L)` and `r format(round(min(100*((rel_otu_data %>% filter(tax_level == 6))$max_num_otus-1), na.rm=T), 1), nsmall=1L)`% more OTUs, respectively, than were observed from the entire dataset. For the datasets included in the current analysis, the use of the cluster splitting heuristic is not worth the loss in clustering quality. However, as datasets become larger, it may be necessary to use the heuristic to clustering the data into OTUs. For example, we were unable to cluster the full human data using less than 45 GB of RAM; however, when we split the dataset at the family level, we were able to cluster the data with the limited resources.


## Discussion
Myriad methods have been proposed for assigning 16S rRNA gene sequences to OTUs that each claim improved performance based on speed, memory usage, representation of taxonomic information, and number of OTUs. Each of these metrics is subjective and do not actually indicate the quality of the clustering. This led us to propose using the MCC as a metric for assessing the quality of clustering, post hoc. Here, we described a new clustering method that seeks to optimize clustering based on an objective criterion that measures clustering quality, a priori. In the OptiClust algorithm clustering is driven by  optimizing a metric that assesses whether any two sequences should be grouped into the same OTU. The result are clusters that are significantly more robust and is efficient in the time and memory required to cluster the sequences into OTUs. This makes it more tractable to analyze large datasets without sacrificing clustering quality as was previously necessary using heuristic methods.

The cluster optimization procedure is dependent on the metric that is chosen for optimization. We employed the MCC because it includes the four values from a confusion matrix. Other algorithms such as the furthest neighbor and nearest neighbor algorithms minimize the number of FP and FN, respectively; however, these suffer because the number of FN and FP are not controlled. Alternatively, one could optimize based on the sensitivity, specificity, or accuracy, which are each based on two values from the confusion matrix or they could optimize based on the F1 score, which is based on three values from the confusion matrix. Because these metrics do not balance all four parameters equally, it is likely that one parameter will dominate in the optimization procedure. For example, optimizing for sensitivity could lead to a large number of FPs. Since we would like to minimize both FPs and FNs and not just the total number of false assignments, we decided to optimize utilizing the MCC. The MCC measures the correlation between observed and predicted classifications and is robust to cases where there is an uneven distribution across the confusion matrix. It is possible that other metrics could be developed and employed for optimization of the clustering.

The OptiClust algorithm is relatively simple. For each sequence it effectively ask whether the MCC value will increase if the sequence is moved to a different OTU including creating a new OTU. If the value does not change, it remains in the current OTU. The algorithm repeats until the MCC value stabilizes. Assuming that the algorithm is seeded with each sequence in a separate OTU, it does not appear that the algorithm converges to a local optimum. Furthermore, execution of the algorithm with different random number generator seeds produces OTU assignments of consistently high quality. Future improvements to the implementation of the algorithm could provide optimization to further improve its speed and susceptibility to find a local optimum. Users are encourage to repeat the OTU assignment several times to confirm that they have found the best OTU assignments.

Our previous MCC-based analysis of numerous clustering algorithms indicated that the average neighbor algorithm consistently produced the best OTU assignments with the DGC-based method using USEARCH also producing robust OTU assignments. The challenge in using the average neighbor algorithm is that it requires a large amount of RAM and is computationally demanding. This led to the development of a splitting approach that divides the clustering across distinct taxonomic groups. The improved performance provided by the OptiClust algorithm likely makes such splitting unnecessary for most current datasets. We have demonstrated that although the OTU assignments made at the genus level are still better than that of other methods, the quality is not as good as that found without splitting. The loss of quality is likely due to misclassification because of limitations in the clustering algorithms and reference databases. The practical significance of such small differences in clustering quality remain to be determined; however, based on the current analysis, it does appear that the number of OTUs is artificially inflated. Regardless, the best clustering quality should be pursued given the available computer resources.

The time required to execute the OptiClust algorithm scaled proportionally to the number of unique sequences raised to the second or third power and the amount of RAM required scaled to the second power. The power for the time requirement is affected by the similarity of the sequences in the dataset with datasets containing more similar sequences having a higher power. Also, the number of unique sequences is the basis for both the amount of time and memory required to complete the algorithm. Both the similarity of sequences and number of unique sequences can be driven by the sequencing error since any errors will increase the number of unique sequences and these sequences will be closely related to the perfect sequence. This underscores the importance of reducing the noise in the sequence data. If sequencing errors are not remediated and are relatively randomly distributed, then it is likely that the algorithm will require an unnecessary amount of time and RAM to complete.

The rapid expansion in sequencing capacity has demanded that the algorithms used to assign 16S rRNA gene sequences to OTUs be efficient while maintaining robust assignments. Although database-based approaches have been proposed to facilitate this analysis, they are limited by their limited coverage of bacterial taxonomy and by the inconsistent process used to name taxa. Thus, the ability to assign sequences to OTUs with an a priori focus on clustering quality will significantly enhance downstream analysis. The development of the OptiClust algorithm represents a significant advance that is likely to have numerous other applications.





## Materials and Methods

***Sequence data and processing steps.***
To evaluate the OptiClust and the other algorithms we created two synthetic sequence collections and four sequence collections generated from previously published studies. The V4 region of the 16S rRNA gene was used from all datasets because it is a popular region that can be fully sequenced with two-fold coverage using the commonly used MiSeq sequencer from Illumina [@Kozich2013]. The method for generating the simulated datasets followed the approach used by Kopylova et al. [-@Kopylova2016] and Schloss [@Schloss2016]. Briefly, we randomly selected 10,000 uniques V4 fragments from 16S rRNA gene sequences that were unique from the SILVA non-redundant database [@Pruesse2007]. A community with an even relative abundance profile was generated by specifying that each sequence had a frequency of 100 reads. A community with a staggered relative abundance profile was generated by specifying that the abundance of each sequence was a randomly drawn integer sampled from a uniform distribution between 1 and 200. Sequence collections collected from human feces [@Baxter2016], murine feces [@Schloss2012], soil [@Johnston2016], and seawater [@Henson2016] were used to characterize the algorithms' performance with natural communities. These sequence collections were all generated using paired 150 or 250 nt reads of the V4 region. We re-processed all of the reads using a common analysis pipeline that included quality score-based error correction [@Kozich2013], alignment against a SILVA reference database [@Pruesse2007; @Schloss2010], screening for chimeras using UCHIME [@Edgar2011], and classification using a naive Bayesian classifier with the RDP training set requiring an 80% confidence score [@Wang2007].


***Implementation of clustering algorithms.***
In addition to the OptiClust algorithm we evaluated ten different *de novo* clustering algorithms. These included three hierarchical algorithms, average neighbor (AN), nearest neighbor (NN), and furthest neighbor (FN), which are implemented in mothur [v.1.39.0; @Schloss2009]. Seven heuristic methods were also used including abundance-based greedy clustering (AGC) and (distance-based greedy clustering) DGC as implemented in USEARCH [v.6.1; @Edgar2010] and VSEARCH [v.X.X.X; @Rognes2015], OTUClust [v.X.X.X; @XXXXXX], SumaClust [v.X.X.X; @XXXXXX], and Swarm [v.2.1.1; @Mah2014]. With the exception of Swarm each of these methods uses distance-based thresholds to report OTU assignments.


***Benchmarking.*** We evaluated the quality of the sequence clustering, reproducibility of the clustering, the speed of clustering, and the amount of memory required to complete the clustering. To assess the quality of the clusters generated by each method, we counted the cells within a confusion matrix that indicated how well the clusterings represented the distances between the pair of sequences [@Schloss2011Assessing]. Pairs of sequences that were in the same OTU and had a distance less than 3% were true positives (TPs), those that were in different OTUs and had a distance greater than 3% were true negatives (TNs), those that were in the same OTU and had a distance greater than 3% were false positives (FPs), and those that were in different OTUs and had a distance less than 3% were false negatives (FNs). To synthesize the matrix into a single metric we used the Matthews Correlation Coefficient using the `sens.spec` command in mothur using the following equations.

$$
MCC = \frac{TP \times TN-FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)} }
$$

To assess the reproducibility of the algorithms we randomized the starting order of each sequence collection ten times and ran each algorithm on each randomized collection. We then measured the MCC for each randomization and quantified their percent coefficient of variation (% CV; 100 times the ratio of the standard deviation to the mean).

To assess how the the memory and time requirements scaled with the number of sequences included in each sequence collection, we randomly subsampled 20, 40, 60, or 80% of the unique sequences in each collection. We obtained 10 subsamples at each depth for each dataset and ran each collection (N= 50 = 5 sequencing depths x 10 replicates) through each of the algorithms. We used the timeout script to quantify the maximum RAM used and the amount of time required to process each sequence collection (https://github.com/pshved/timeout). We limited each algorithm to 45 GB of RAM and 50 hours using a single processor.


***Data and code availability.*** The workflow utilized commands in GNU make (v.3.81), GNU bash (v.4.1.2), mothur [v.1.39.0; @Schloss2009], and R [v.`r paste(version$major, version$minor, sep='.')`; @language2015]. Within R we utilized the wesanderson [v.X.X.X; @XXXXXX], dplyr [v.X.X.X; @XXXXXX], tidyr [v.X.X.X; @XXXXXX], cowplot [v.X.X.X; @XXXXXX], and ggplot2 [v.X.X.X; @XXXXXX] packages. A reproducible version of this manuscript and analysis is available at https://github.com/SchlossLab/Westcott_OptiClust_mSystems_2015.


\newpage


## Figures

**Figure 1. Comparison of de novo clustering algorithms.**  Plot of MCC (A), number of OTUs (B), and execution times (C) for the comparison of *de novo* clustering algorithms when applied to four natural and two synthetic datasets. The first three columns of each figure contain the results of clustering the datasets (i) seeding the algorithm with one sequence per OTU and allowing the algorithm to proceed until the MCC value no longer changed; (ii) seeding the algorithm with one sequence per OTU and allowing the algorithm to proceed until the MCC changed by less than 0.0001; (iii) seeding the algorithm with all of the sequences in one OTU and allowing the algorithm to proceed until the MCC value no longer changed. The human dataset could not be clustered by the average neighbor, Sumaclust, USEARCH, or OTUCLUST with less than 45 GB of RAM or 50 hours of execution time. The median of 10 re-orderings of the data is presented for each method and dataset. The confidence interval is indicated by the error bars, which are typically smaller than the plotting symbol.

**Figure 2. OptiClust performance** The average execution time (A) and memory usage (B) required to cluster the four natural datasets. The confidence intervals indicate the range between the minimum and maximum values. The y-axis is scaled by the square root to demonstrate the relationship between the time and memory requirements relative to the number of unique sequences squared.

**Figure 3. Effects of taxonomically splitting the datasets on clustering quality.** The datasets were split at each taxonomic level based on their classification using a naive Bayesian classifier and clustered using average neighbor, VSEARCH-based DGC, and OptiClust.

**Supplemental text.** Worked example of how OptiClust algorithm clusters sequences into OTUs.

\newpage

**Table 1. Description of datasets used to evaluate the OptiClust algorithm and compare its performance to other algorithms.**



## References
