---
title: "**OptiClust: Improved method for assigning amplicon-based sequence data to operational taxonomic units**"
bibliography: references.bib
output:
  pdf_document:
    keep_tex: true
    includes:
      in_header: header.tex
    fig_caption: false
csl: msphere.csl
fontsize: 11pt
geometry: margin=1.0in
---


```{r knitr_settings, eval=TRUE, echo=FALSE, cache=FALSE}
library(dplyr, warn.conflicts=FALSE)
library(tidyr)
library(knitr)

opts_chunk$set("tidy" = TRUE)
opts_chunk$set("echo" = FALSE)
opts_chunk$set("eval" = TRUE)
opts_chunk$set("warning" = FALSE)
opts_chunk$set("cache" = FALSE)

inline_hook <- function(x){
	print(x)
	if(is.numeric(x)){
		if(abs(x - round(x)) < .Machine$double.eps^0.5){
			paste(format(x,big.mark=',', digits=0, scientific=FALSE))
		} else {
			paste(format(x,big.mark=',', digits=2, nsmall=2, scientific=FALSE))
		}

	} else {
    	paste(x)      
	}
}
knitr::knit_hooks$set(inline=inline_hook)

basic_methods <- c('an', 'fn', 'nn', 'otuclust', 'sumaclust', 'swarm',
										'uagc', 'udgc', 'vagc_1', 'vdgc_1', 'mcc')

```


\begin{center}

Running title: OptiClust: Optimized Clustering


\vspace{25mm}
Sarah L. Westcott and Patrick D. Schloss${^\dagger}$

\vspace{30mm}

$\dagger$ To whom correspondence should be addressed: pschloss@umich.edu

Department of Microbiology and Immunology, University of Michigan, Ann Arbor, MI
\end{center}


\newpage
\linenumbers

## Abstract
Assignment of 16S rRNA gene sequences to operational taxonomic units (OTUs) is a computational bottleneck in the process of analyzing microbial communities. Although this has been an active area of research, it has been difficult to overcome the time and memory demands while improving the quality of the OTU assignments. Here we developed a new OTU assignment algorithm that iteratively reassigns sequences to new OTUs to optimize the Matthews correlation coefficient (MCC), a measure of the quality of OTU assignments. To assess the new algorithm, OptiClust, we compared it to ten other algorithms using 16S rRNA gene sequences from two simulated and four natural communities. Using the OptiClust algorithm, the MCC values averaged 15.2 and 16.5% higher than the OTUs generated when we used the average neighbor and distance-based greedy clustering with VSEARCH, respectively. Furthermore, on average, OptiClust was 94.6-times faster than the average neighbor algorithm and just as fast as distance-based greedy clustering with VSEARCH. An empirical analysis of the efficiency of the algorithms showed that the time and memory required to perform the algorithm scaled quadratically with the number of unique sequences in the dataset. The significant improvement in the quality of the OTU assignments over previously existing methods will significantly enhance downstream analysis by limiting the splitting of similar sequences into separate OTUs and merging of dissimilar sequences into the same OTU. The development of the OptiClust algorithm represents a significant advance that is likely to have numerous other applications.

## Importance
The analysis of microbial communities from diverse environments using 16S rRNA gene sequencing has expanded our knowledge of the biogeography of microorganisms. An important step in this analysis is the assignment of sequences into taxonomic groups based on their similarity to sequences in a database or based on their similarity to each other, irrespective of a database. In this study, we present a new algorithm for the latter approach. The algorithm, OptiClust, seeks to optimize a metric of assignment quality by shuffling sequences between taxonomic groups. We found that OptiClust produces more robust assignments and does so in a rapid and memory efficient manner. This advance will allow for a more robust analysis of microbial communities and the factors that shape them.


\newpage

## Introduction

Amplicon-based sequencing has provided incredible insights into Earth's microbial biodiversity [@Schloss2016b; @Locey2016]. It has become common for studies to include sequencing millions of 16S rRNA gene sequences across hundreds of samples [@Rideout2014; @Huttenhower2012]. This is three to four orders of magnitude greater sequencing depth than was previously achieved using Sanger sequencing [@Eckburg2005; @Elshahed2008]. The increased sequencing depth has revealed novel taxonomic diversity that is not adequately represented in reference databases [@Schloss2016b; @Rideout2014]. However, the advance has forced re-engineering of methods to overcome the rate and memory limiting steps in computational pipelines that process raw sequences through the generation of tables containing the number of sequences in different taxa for each sample [e.g. @Kozich2013; @Schloss2009a; @Edgar2011; @Wang2007]. A critical component to these pipelines has been the assignment of amplicon sequences to taxonomic units that are ether defined based on similarity to a reference or operationally based on the similarity of the sequences to each other within the dataset [@Schloss2009b; @Caporaso2010].

A growing number of algorithms have been developed to cluster sequences into OTUs. These algorithms can be classified into three general categories. The first category of algorithms has been termed closed-reference or phylotyping [@Schloss2011; @NavasMolina2013]. Sequences are compared to a reference collection and clustered based on the reference sequences that they are similar to. This approach is fast; however, the method struggles when a sequence is similar to multiple reference sequences that may have different taxonomies and when it is not similar to sequences in the reference [@Westcott2015]. The second category of algorithms has been called *de novo* because they assign sequences to OTUs without the use of a reference [@NavasMolina2013]. These include hierarchical algorithms such as nearest, furthest, and average neighbor [@Schloss2005] and algorithms that employ heuristics such as abundance or distance-based greedy clustering as implemented in USEARCH [@Edgar2010] or VSEARCH [@Rognes2016], Sumaclust, OTUCLUST [@Albanese2015], and Swarm [@Mah2014]. *De novo* methods are agglomerative and tend to be more computationally intense. It has proven difficult to know which method generates the best assignments. A third category of algorithm is open reference clustering, which is a hybrid approach [@NavasMolina2013; @Rideout2014]. Here sequences are assigned to OTUs using closed-reference clustering and sequences that are not within a threshold of a reference sequence are then clustered using a *de novo* approach. This category blends the strengths and weaknesses of the other method and adds the complication that closed-reference and *de novo* clustering use different OTU definitions. These three categories of algorithms take different approaches to handling large datasets to minimize the time and memory requirements while attempting to assign sequences to meaningful OTUs.

Several metrics have emerged for assessing the quality of OTU assignment algorithms. These have included the time and memory required to run the algorithm [@Sun2009; @Cai2011; @Rideout2014; @Mah2014], agreement between OTU assignments and the sequences' taxonomy [@Edgar2013; @Mah2014; @Mah2015; @Barriuso2011; @Bonder2012; @Chen2013; @Huse2010; @May2014; @Cai2011; @Sun2011; @White2010; @AlGhalith2016], sensitivity of an algorithm to stochastic processes [@He2015], the number of OTUs generated by the algorithm [@Edgar2013; @Kopylova2016], and the ability to regenerate the assignments made by other algorithms [@Schmidt2014; @Rideout2014]. Unfortunately, these methods fail to directly quantify the quality of the OTU assignments. An algorithm may complete with minimal time and memory requirements or generate an idealized number of OTUs, but the composition of the OTUs could be incorrect. These metrics also tend to be subjective. For instance, a method may appear to recapitulate the taxonomy of a synthetic community with known taxonomic structure, but do a poor job when applied to real communities with poorly defined taxonomic structure or for sequences that are prone to misclassification. As an alternative, we developed an approach to objectively benchmark the clustering quality of OTU assignments [@Schloss2016a; @Westcott2015; @Schloss2011]. This approach counts the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) based on the pairwise distances. Sequence pairs that are within the user-specified threshold and are clustered together represent TPs and those in different OTUs are FNs. Those sequence pairs that have a distance larger than the threshold and are not clustered in the same OTU are TNs and those in the same OTU are FPs. These values can be synthesized into a single correlation coefficient, the Matthews correlation coefficient (MCC), which measures the correlation between observed and predicted classifications and is robust to cases where there is an uneven distribution across the confusion matrix [@Matthews1975]. Consistently, the average neighbor algorithm was identified as among the best or the best algorithm. Other hierarchical algorithms such as furthest and nearest neighbor, which do not permit the formation of FPs or FNs, respectively, fared significantly worse. The distance-based greedy clustering as implemented in VSEARCH has also performed well. The computational resources required to complete the average neighbor algorithm can be significant for large datasets and so there is a need for an algorithm that efficiently produces consistently high quality OTU assignments.

These benchmarking efforts have assessed the quality of the clusters after the completion of the algorithm. In the current study we developed and benchmarked a new *de novo* clustering algorithm that uses real time calculation of the MCC to direct the progress of the clustering. The result is the OptiClust algorithm, which produces significantly better sequence assignments while making efficient use of computational resources.


## Results

***OptiClust algorithm.***
The OptiClust algorithm uses the pairs of sequences that are within a desired threshold of each other (e.g. 0.03), a list of all sequence names in the dataset, and the metric that should be used to assess clustering quality. A detailed description of the algorithm is provided for a toy dataset in the Supplementary Material. Briefly, the algorithm starts by placing each sequence either within its own OTU or into a single OTU. The algorithm proceeds by interrogating each sequence and re-calculating the metric for the cases where the sequence stays in its current OTU, is moved to each of the other OTUs, or is moved into a new OTU. The location that results in the best clustering quality indicates whether the sequence should remain in its current OTU or be moved to a different or new OTU. Each iteration consists of interrogating every sequence in the dataset. Although numerous options are available for optimizing the clusters and for assessing the quality of the clusters within the mothur-based implementation of the algorithm (e.g. sensitivity, specificity, accuracy, F1-score, etc.), the default metric for optimization and assessment is MCC because it includes all four parameters from the confusion matrix (Figure S1; Table S1). The algorithm continues until the optimization metric stabilizes or until it reaches a defined stopping criteria.


```{r performance_analysis}
perf <- read.table(file="data/processed/cluster_data.summary", header=T) %>%
				filter(frac == 1.0, method %in% basic_methods) %>%
				select(dataset, method, cluster_secs, cluster_kb, mcc, num_otus) %>%
				group_by(dataset, method) %>%
				summarize(
					mean_secs = mean(cluster_secs, na.rm=T),
					mean_kb = mean(cluster_kb, na.rm=T),
					mean_mcc = mean(mcc, na.rm=T),
					mean_num_otus = mean(num_otus, na.rm=T)
				)
perf_summary <- perf %>%
				group_by(method) %>%
				summarize(
					mean_mcc = mean(mean_mcc, na.rm=T),
					mean_secs = mean(mean_secs, na.rm=T)
				) %>%
				mutate(
					rel_mcc = mean_mcc/mean_mcc[method=='mcc'],
					rel_secs = mean_secs/mean_secs[method=='mcc']
				)

mcc_rel_an <-100*(1-perf_summary %>% filter(method=="an") %>% select(rel_mcc))
mcc_rel_vdgc <- 100*(1-perf_summary %>% filter(method=="vdgc_1") %>% select(rel_mcc))

secs_rel_an <- perf_summary %>% filter(method=="an") %>% select(rel_secs)
secs_rel_vdgc <- perf_summary %>% filter(method=="vdgc_1") %>% select(rel_secs)

mcc_sobs_cor <- cor.test(perf$mean_num_otus, perf$mean_mcc, method="spearman")

stopifnot(round(1/secs_rel_vdgc, 1) == 1)
```

***OptiClust-generated OTUs are more robust than those from other methods.***
To evaluate the OptiClust algorithm and compare its performance to other algorithms, we utilized six datasets including two synthetic communities and four previously published large datasets generated from soil, marine, human, and murine samples (Table 1). When we seeded the OptiClust algorithm with each sequence in a separate OTU and ran the algorithm until complete convergence, the MCC values averaged `r round(mcc_rel_an, 1)` and `r round(mcc_rel_vdgc, 1)`% higher than the OTUs using average neighbor and distance-based greedy clustering (DGC) with VSEARCH, respectively (Figure 1; Table S1). The number of OTUs formed by the various methods was negatively correlated with their MCC value ($\rho$=`r round(mcc_sobs_cor$estimate, 2)`; p`r p<-mcc_sobs_cor$p.value; ifelse(p<0.001, "<0.001", paste0("=", p))`). The OptiClust algorithm was considerably faster than the hierarchical algorithms and somewhat slower than the heuristic-based algorithms. Across the six datasets, the OptiClust algorithm was `r round(secs_rel_an, 1)`-times faster than average neighbor and just as fast as DGC with VSEARCH. The human dataset was a challenge for a number of the algorithms. OTUCLUST and SumaClust were unable to cluster the human dataset in less than 50 hours and the average neighbor algorithm required more than 45 GB of RAM. The USEARCH-based methods were unable to cluster the human data using the 32-bit free version of the software that limits the amount of RAM to approximately 3.5 GB. These data demonstrate that OptiClust generated significantly more robust OTU assignments than existing methods across a diverse collection of datasets with performance that was comparable to popular methods.


```{r stopping_analysis}
steps <- read.table(file="data/processed/mcc_steps.summary", header=T) %>%
					filter(frac == 1.0, dataset!="even", dataset!="staggered") %>%
					select(-rep, -frac, -method, -contains("_secs_cluster")) %>%
					group_by(dataset) %>%
					summarize(med_full_secs = median(full_secs),
							per_diff_mcc = 100 * mean((full_mcc-close_mcc)/full_mcc),
							diff_numotus = median(close_num_otus - full_num_otus),
							per_diff_numotus = 100 * mean((close_num_otus - full_num_otus)/full_num_otus),
							ratio_secs = mean(full_secs/close_secs),
							med_close_steps = median(close_steps),
							med_full_steps = median(full_steps)
					)
```
***OptiClust stopping criteria.***
By default, the mothur-based implementation of the algorithm stops when the optimization metric changes by less than 0.0001; however, this can be altered by the user. This implementation also allows the user to stop the algorithm if a maximum number of iterations is exceeded. By default mothur uses a maximum value of 100 iterations. The justification for allowing incomplete convergence was based on the observation that numerous iterations are performed that extend the time required to complete the clustering with minimal improvement in clustering (Figure S2). We evaluated the results of clustering to partial convergence (i.e. a change in the MCC value that was less than 0.0001) or until complete convergence of the MCC value (i.e. until it did not change between iterations) when seeding the algorithm with each sequence in a separate OTU (Figure 1). The small difference in MCC values between the output from partial and complete convergence resulted in a difference in the median number of OTUs that ranged between `r paste(format(round(range(steps$diff_numotus), 1), nsmall=1L), collapse=" and ")` OTUs. This represented a difference of less than `r format(round(max(steps$per_diff_numotus), 2), nsmall=1L)`%. Among the four natural datasets, between `r min(steps$med_close_steps)` and `r max(steps$med_close_steps)` were needed to achieve partial convergence and between `r min(steps$med_full_steps)` and `r round(max(steps$med_full_steps))` iterations were needed to reach full convergence. The additional steps required between `r paste(format(round(range(steps$ratio_secs), 1), nsmall=1L), collapse=" and ")` times longer to complete the algorithm. These results suggest that achieving full convergence of the optimization metric adds computational effort; however, considering full convergence took between `r paste(round(range(steps$med_full_secs/60), 0), collapse=" and ")` minutes the extra effort was relatively small. Although the mothur's default setting is partial convergence, the remainder of our analysis used complete convergence to be more conservative.


```{r aggregate_analysis}
agg <- read.table(file="data/processed/cluster_data.summary", header=T, stringsAsFactors=F) %>%
			filter(frac==1.0, method %in% (c("mcc", "mcc_agg"))) %>%
			select(dataset, method, cluster_secs, mcc, num_otus) %>%
			group_by(dataset, method) %>%
			summarize(
				mean_secs = mean(cluster_secs, na.rm=T),
				mean_mcc = mean(mcc, na.rm=T),
				mean_num_otus = mean(num_otus, na.rm=T)
			) %>%
			group_by(dataset) %>%
			summarize(
				fold_secs = mean_secs[method=="mcc_agg"]/mean_secs[method=="mcc"],
				per_diff_mcc = 100*(1-mean_mcc[method=="mcc_agg"]/mean_mcc[method=="mcc"]),
				per_diff_num_otus =100*(1-mean_num_otus[method=="mcc_agg"]/mean_num_otus[method=="mcc"])
			)
```

***Effect of seeding OTUs on OptiClust performance.***
By default the mothur implementation of the OptiClust algorithm starts with each sequence in a separate OTU. An alternative approach is to start with all of the sequences in a single OTU. We found that the MCC values for clusters generated seeding OptiClust with the sequences as a single OTU were between `r paste(round(range(agg$per_diff_mcc), 1), collapse=" and ")`% lower than when seeding the algorithm with sequences in separate OTUs (Figure 1). Interestingly, with the exception of the `r agg[which.min(agg$per_diff_num_otus),"dataset"]` dataset (`r format(abs(round(agg[which.min(agg$per_diff_num_otus),"per_diff_num_otus"], 1)), nsmall=1L)`% more OTUs), the number of OTUs was as much as `r format(round(agg[which.max(agg$per_diff_num_otus),"per_diff_num_otus"], 1), nsmall=1L)`% lower (`r agg[which.max(agg$per_diff_num_otus),"dataset"]`) than when the algorithm was seeded with sequence in separate OTUs. Finally, the amount of time required to cluster the data when the algorithm was seeded with a single OTU was between `r paste(format(round(range(agg$fold_secs), 1), nsmall=1L), collapse=" and ")`-times longer than if sequences were seeded as separate OTUs. This analysis demonstrates that seeding the algorithm with sequences as separate OTUs resulted in the best OTU assignments in the shortest amount of time.


```{r stability_analysis}
stability <- read.table(file="data/processed/cluster_data.summary",header=T) %>%
						filter(frac == 1.0, method %in% basic_methods) %>%
						select(dataset, method, mcc, num_otus) %>%
						group_by(dataset, method) %>%
						summarize(
							cov_mcc = sd(mcc) / mean(mcc) * 100,
							cov_num_otus = sd(num_otus) / mean(num_otus) * 100
						) %>%
						group_by(method) %>%
						summarize(
							med_cov_mcc = median(cov_mcc, na.rm=T),
							med_cov_num_otus = median(cov_num_otus, na.rm=T)
						)
```

***OptiClust-generated OTUs are as stable as those from other algorithms.***
One concern that many have with *de novo* clustering algorithms is that their output is sensitive to the initial order of the sequences because each algorithm must break ties where a sequence could be assigned to multiple OTUs. An additional concern specific to the OptiClust algorithm is that it may stabilize at a local optimum. To evaluate these concerns we compared the results obtained using ten randomizations of the order that sequences were given to the algorithm. The median coefficient of variation across the six datasets for MCC values obtained from the replicate clusterings using OptiClust was `r format(round(stability %>% filter(method=="mcc") %>% select(med_cov_mcc), 1), nsmall=1L)`% (Figure 1). We also measured the coefficient of variation for the number of OTUs across the six datasets for each method. The median coefficient of variation for the number of OTUs generated using OptiClust was `r format(round(stability %>% filter(method=="mcc") %>% select(med_cov_num_otus), 1), nsmall=1L)`%. Confirming our previous results [@Westcott2015], all of the methods we tested were stable to stochastic processes. Of the methods that involved randomization, the coefficient of variation for MCC values was considerably smaller with OptiClust than the other methods and the coefficient of variation for the number of OTUs was comparable to the other methods. The variation observed in clustering quality suggested that the algorithm does not appear to converge to a locally optimum MCC value. More importantly, the random variation does yield output of a similarly high quality.


```{r scaling_analysis}
datasets <- c('human', 'mice', 'marine', 'soil')

speed_data <- read.table(file="data/processed/mcc_steps.summary", header=T)

speed_models <- speed_data %>%
		filter(dataset %in% datasets) %>%
		select(dataset, frac, full_secs_cluster, full_steps) %>%
		group_by(dataset) %>%
		do(
			model = nls((full_secs_cluster/full_steps) ~ b * frac ^ z,
														start = list(b = 1000, z = 2), data= .)
		)

speed_coef <- c(
		speed_models[speed_models$dataset=="human",2][[1]][[1]]$m$getPars()["z"],
		speed_models[speed_models$dataset=="mice",2][[1]][[1]]$m$getPars()["z"],
		speed_models[speed_models$dataset=="marine",2][[1]][[1]]$m$getPars()["z"],
		speed_models[speed_models$dataset=="soil",2][[1]][[1]]$m$getPars()["z"]
	)
names(speed_coef) <- datasets

memory_data <- read.table(file="data/processed/cluster_data.summary", header=T)

memory_models <- memory_data %>%
		filter(dataset %in% datasets, method == "mcc") %>%
		mutate(cluster_gb=cluster_kb/1048000) %>%
		select(dataset, frac, cluster_gb) %>%
		group_by(dataset) %>%
		do(model = nls((cluster_gb) ~ b * frac ^ z, start = list(b = 1e6, z = 3), data= .))

memory_coef <- c(
		memory_models[memory_models$dataset=="human",2][[1]][[1]]$m$getPars()["z"],
		memory_models[memory_models$dataset=="mice",2][[1]][[1]]$m$getPars()["z"],
		memory_models[memory_models$dataset=="marine",2][[1]][[1]]$m$getPars()["z"],
		memory_models[memory_models$dataset=="soil",2][[1]][[1]]$m$getPars()["z"]
	)
names(memory_coef) <- datasets

```

***Time and memory required to complete Optimization-based clustering scales efficiently.***
Although not as important as the quality of clustering, the amount of time and memory required to assign sequences to OTUs is a legitimate concern. We observed that the time required to complete the OptiClust algorithm (Figure 1C) paralleled the number of pairwise distances that were smaller than 0.03 (Table 1). To further evaluate how the speed and memory usage scaled with the number of sequences in the dataset, we measured the time required and maximum RAM usage to cluster 20, 40, 60, 80, and 100% of the unique sequences from each of the natural datasets using the OptiClust algorithm (Figure 2). Within each iteration of the algorithm, each sequence is compared to every other sequence and each comparison requires a recalculation of the confusion matrix. This would result in a worst case algorithmic complexity on the order of N^3^, where N is the number of unique sequences. Because the algorithm only needs to keep track of the sequence pairs that are within the threshold of each other, it is likely that the implementation of the algorithm is more efficient. To empirically determine the algorithmic complexity, we fit a power law function to the data in Figure 2A. We observed power coefficients between `r paste(format(round(range(speed_coef), 1), nsmall=1L), collapse=" and ")` for the `r paste(names(speed_coef[c(which.min(speed_coef), which.max(speed_coef))]), collapse=" and ")` datasets, respectively. The algorithm requires storing a matrix that contains the pairs of sequences that are close to each other as well as a matrix that indicates which sequences are clustered together. The memory required to store these matrices is on the order of N^2^, where N is the number of unique sequences. In fact, when we fit a power law function to the data in Figure 2B, the power coefficients were  `r format(round(median(memory_coef), 1), nsmall=1L)`. Using the four natural community datasets, doubling the number of sequences in a dataset would increase the time required to cluster the data by 4 to 8-fold and increase the RAM required by 4-fold. It is possible that future improvements to the implementation of the algorithm could improve this performance.


```{r split_analysis}
datasets <- c('soil', 'marine', 'mice', 'human')

full_data <- read.table(file="data/processed/cluster_data.summary", header=T, stringsAsFactors=FALSE)

full_data$method <- gsub("^mcc$", "mcc_split1_8", full_data$method)
full_data$method <- gsub("^vdgc_1$", "vdgc_split1_8", full_data$method)
full_data$method <- gsub("^an$", "an_split1_8", full_data$method)

split_data <- full_data %>%
				mutate(method = gsub("^mcc$", "mcc_split1_8", method)) %>%
				mutate(method = gsub("^vdgc_1$", "vdgc_split1_8", method)) %>%
				mutate(method = gsub("^an$", "an_split1_8", method)) %>%
				filter(
						grepl("split", method),
						frac==1.0,
						dataset==datasets
				) %>%
				select(dataset, method, mcc, num_otus) %>%
				separate(method, into=c("method", "split", "processors"), sep="_") %>%
				mutate(tax_level=as.numeric(gsub("split", "", split))) %>%
				select(-split, -processors) %>%
				gather(metric, value, mcc, num_otus) %>%
				group_by(dataset, method, metric, tax_level) %>%
				summarize(
					mean=if(sum(!is.na(value))>0){mean(value, na.rm=TRUE)}	else { NA }
				)

rel_mcc_data <- split_data %>%
			filter(metric == "mcc") %>%
			group_by(dataset, method, tax_level) %>%
			summarize(mean = mean(mean, na.rm=T)) %>%
			group_by(dataset, method) %>%
			mutate(rel_mean=mean/mean[tax_level==1]) %>%
			group_by(method, tax_level) %>%
			summarize(min_mcc = min(rel_mean, na.rm=T))

rel_otu_data <- split_data %>%
			filter(metric == "num_otus") %>%
			group_by(dataset, method, tax_level) %>%
			summarize(mean = mean(mean, na.rm=T)) %>%
			group_by(dataset, method) %>%
			mutate(rel_mean=mean/mean[tax_level==1]) %>%
			group_by(method, tax_level) %>%
			summarize(max_num_otus = max(rel_mean, na.rm=T))

```

***Cluster splitting heuristic generates OTUs that are as good as non-split approach.***
We previously described a heuristic to accelerate OTU assignments where sequences were first classified to taxonomic groups and within each taxon sequences were assigned to OTUs using the average neighbor clustering algorithm [@Schloss2011]. This method is similar to open reference clustering except that in our approach all sequences are subjected to *de novo* clustering following classification whereas in open reference clustering only those sequences that cannot be classified are subjected to *de novo* clustering. Our cluster splitting approach accelerated the clustering and reduced the memory requirements because the number of unique sequences was effectively reduced by splitting sequences across taxonomic groups. Furthermore, because sequences in different taxonomic groups are assumed to belong to different OTUs they are independent, which permits parallelization and additional reduction in computation time. Reduction in clustering quality is encountered in this approach if there are errors in classification or if two sequences within the desired threshold belong to different taxonomic groups. It is expected that these errors would increase as the taxonomic level goes from kingdom to genus. To characterize the clustering quality, we classified each sequence at each taxonomic level and calculated the MCC values using OptiClust, average neighbor, and DGC with VSEARCH when splitting at each taxonomic level (Figure 3). For each method, the MCC values decreased as the taxonomic resolution increased; however, the decrease in MCC was not as large as the difference between clustering methods. As the resolution of the taxonomic levels increased, the clustering quality remained high, relative to clusters formed from the entire dataset (i.e. kingdom-level). The MCC values when splitting the datasets at the class and genus levels were within `r format(round(min(100*(rel_mcc_data %>% filter(tax_level == 3))$min_mcc), 1), nsmall=1L)` and `r format(round(min(100*(rel_mcc_data %>% filter(tax_level == 6))$min_mcc), 1), nsmall=1L)`%, respectively, of the MCC values obtained from the entire dataset. These decreases in MCC value resulted in the formation of as many as `r format(round(min(100*((rel_otu_data %>% filter(tax_level == 3))$max_num_otus-1), na.rm=T), 1), nsmall=1L)` and `r format(round(min(100*((rel_otu_data %>% filter(tax_level == 6))$max_num_otus-1), na.rm=T), 1), nsmall=1L)`% more OTUs, respectively, than were observed from the entire dataset. These errors were due to the generation of additional false negatives due to splitting similar sequences into different taxonomic groups. For the datasets included in the current analysis, the use of the cluster splitting heuristic was probably not worth the loss in clustering quality. However, as datasets become larger, it may be necessary to use the heuristic to clustering the data into OTUs.


## Discussion
Myriad methods have been proposed for assigning 16S rRNA gene sequences to OTUs. Each claim improved performance based on speed, memory usage, representation of taxonomic information, and number of OTUs. Each of these metrics is subjective and do not actually indicate the quality of the clustering. This led us to propose using the MCC as a metric for assessing the quality of clustering, post hoc. Here, we described a new clustering method that seeks to optimize clustering based on an objective criterion that measures clustering quality in real time. In the OptiClust algorithm, clustering is driven by optimizing a metric that assesses whether any two sequences should be grouped into the same OTU. The result is clusters that are significantly more robust and is efficient in the time and memory required to cluster the sequences into OTUs. This makes it more tractable to analyze large datasets without sacrificing clustering quality as was previously necessary using heuristic methods.

The cluster optimization procedure is dependent on the metric that is chosen for optimization. We employed the MCC because it includes the four values from a confusion matrix. Other algorithms such as the furthest neighbor and nearest neighbor algorithms minimize the number of FP and FN, respectively; however, these suffer because the number of FN and FP are not controlled, respectively [@Schloss2005; @Schloss2011]. Alternatively, one could optimize based on the sensitivity, specificity, or accuracy, which are each based on two values from the confusion matrix or they could optimize based on the F1-score, which is based on three values from the confusion matrix. Because these metrics do not balance all four parameters equally, it is likely that one parameter will dominate in the optimization procedure. For example, optimizing for sensitivity could lead to a large number of FPs. More FPs increases the number of OTUs while more FNs collapses OTUs together. It is difficult to know which is worse since community richness and diversity are linked to the number of OTUs. In addition, increasing the number of FNs would overstate the differences between communities while increasing the number of FPs would overstate their similarity. Therefore, it is important to jointly minimize the number of FPs and FNs. With this in mind, we decided to optimize utilizing the MCC. It is possible that other metrics that balance the four parameters could be developed and employed for optimization of the clustering.

The OptiClust algorithm is relatively simple. For each sequence it effectively asks whether the MCC value will increase if the sequence is moved to a different OTU including creating a new OTU. If the value does not change, it remains in the current OTU. The algorithm repeats until the MCC value stabilizes. Assuming that the algorithm is seeded with each sequence in a separate OTU, it does not appear that the algorithm converges to a local optimum. Furthermore, execution of the algorithm with different random number generator seeds produces OTU assignments of consistently high quality. Future improvements to the implementation of the algorithm could provide optimization to further improve its speed and susceptibility to find a local optimum. Users are encouraged to repeat the OTU assignment several times to confirm that they have found the best OTU assignments.

Our previous MCC-based analysis of clustering algorithms indicated that the average neighbor algorithm consistently produced the best OTU assignments with the DGC-based method using USEARCH also producing robust OTU assignments. The challenge in using the average neighbor algorithm is that it requires a large amount of RAM and is computationally demanding. This led to the development of a splitting approach that divides the clustering across distinct taxonomic groups [@Schloss2011]. The improved performance provided by the OptiClust algorithm likely makes such splitting unnecessary for most current datasets. We have demonstrated that although the OTU assignments made at the genus level are still better than that of other methods, the quality is not as good as that found without splitting. The loss of quality is likely due to misclassification because of limitations in the clustering algorithms and reference databases. The practical significance of such small differences in clustering quality remain to be determined; however, based on the current analysis, it does appear that the number of OTUs is artificially inflated. Regardless, the best clustering quality should be pursued given the available computer resources.

The time and memory required to execute the OptiClust algorithm scaled proportionally to the number of unique sequences raised to the second power. The power for the time requirement is affected by the similarity of the sequences in the dataset with datasets containing more similar sequences having a higher power. Also, the number of unique sequences is the basis for both the amount of time and memory required to complete the algorithm. Both the similarity of sequences and number of unique sequences can be driven by the sequencing error since any errors will increase the number of unique sequences and these sequences will be closely related to the perfect sequence. This underscores the importance of reducing the noise in the sequence data [@Kozich2013]. If sequencing errors are not remediated and are relatively randomly distributed, then it is likely that the algorithm will require an unnecessary amount of time and RAM to complete.

The rapid expansion in sequencing capacity has demanded that the algorithms used to assign 16S rRNA gene sequences to OTUs be efficient while maintaining robust assignments. Although database-based approaches have been proposed to facilitate this analysis, they are limited by their limited coverage of bacterial taxonomy and by the inconsistent process used to name taxa. The ability to assign sequences to OTUs using an algorithm that optimizes clustering by directly measuring quality will significantly enhance downstream analysis. The development of the OptiClust algorithm represents a significant advance that is likely to have numerous other applications.





## Materials and Methods

***Sequence data and processing steps.***
To evaluate the OptiClust and the other algorithms we created two synthetic sequence collections and four sequence collections generated from previously published studies. The V4 region of the 16S rRNA gene was used from all datasets because it is a popular region that can be fully sequenced with two-fold coverage using the commonly used MiSeq sequencer from Illumina [@Kozich2013]. The method for generating the simulated datasets followed the approach used by Kopylova et al. [-@Kopylova2016] and Schloss [-@Schloss2016a]. Briefly, we randomly selected 10,000 uniques V4 fragments from 16S rRNA gene sequences that were unique from the SILVA non-redundant database [@Pruesse2007]. A community with an even relative abundance profile was generated by specifying that each sequence had a frequency of 100 reads. A community with a staggered relative abundance profile was generated by specifying that the abundance of each sequence was a randomly drawn integer sampled from a uniform distribution between 1 and 200. Sequence collections collected from human feces [@Baxter2016], murine feces [@Schloss2012], soil [@Johnston2016], and seawater [@Henson2016] were used to characterize the algorithms' performance with natural communities. These sequence collections were all generated using paired 150 or 250 nt reads of the V4 region. We re-processed all of the reads using a common analysis pipeline that included quality score-based error correction [@Kozich2013], alignment against a SILVA reference database [@Pruesse2007; @Schloss2010], screening for chimeras using UCHIME [@Edgar2011], and classification using a naive Bayesian classifier with the RDP training set requiring an 80% confidence score [@Wang2007].


***Implementation of clustering algorithms.***
In addition to the OptiClust algorithm we evaluated ten different *de novo* clustering algorithms. These included three hierarchical algorithms, average neighbor, nearest neighbor, and furthest neighbor, which are implemented in mothur (v.1.39.0) [@Schloss2009b]. Seven heuristic methods were also used including abundance-based greedy clustering (AGC) and (distance-based greedy clustering) DGC as implemented in USEARCH (v.6.1) [@Edgar2010] and VSEARCH (v.2.3.3) (@Rognes2016], OTUCLUST (v.0.1) [@Albanese2015], SumaClust (v.1.0.20), and Swarm (v.2.1.9) [@Mah2014]. With the exception of Swarm each of these methods uses distance-based thresholds to report OTU assignments. We also evalauted the ability of OptiClust to optimize to metrics other than MCC. These included accuracy, F1-score, negative predictive value, positive predictive value, false discovery rate, senitivity, specificity, the sum of TPs and TNs, the sum of FPs and FNs, and the number of FNs, FPs, TNs, and TPs (Figure S1; Table S1).


***Benchmarking.*** We evaluated the quality of the sequence clustering, reproducibility of the clustering, the speed of clustering, and the amount of memory required to complete the clustering. To assess the quality of the clusters generated by each method, we counted the cells within a confusion matrix that indicated how well the clusterings represented the distances between the pair of sequences [@Schloss2011]. Pairs of sequences that were in the same OTU and had a distance less than 3% were true positives (TPs), those that were in different OTUs and had a distance greater than 3% were true negatives (TNs), those that were in the same OTU and had a distance greater than 3% were false positives (FPs), and those that were in different OTUs and had a distance less than 3% were false negatives (FNs). To synthesize the matrix into a single metric we used the Matthews correlation coefficient using the `sens.spec` command in mothur using the following equations.

$$
MCC = \frac{TP \times TN-FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)} }
$$

To assess the reproducibility of the algorithms we randomized the starting order of each sequence collection ten times and ran each algorithm on each randomized collection. We then measured the MCC for each randomization and quantified their percent coefficient of variation (% CV; 100 times the ratio of the standard deviation to the mean).

To assess how the the memory and time requirements scaled with the number of sequences included in each sequence collection, we randomly subsampled 20, 40, 60, or 80% of the unique sequences in each collection. We obtained 10 subsamples at each depth for each dataset and ran each collection (N= 50 = 5 sequencing depths x 10 replicates) through each of the algorithms. We used the `timeout` script to quantify the maximum RAM used and the amount of time required to process each sequence collection (https://github.com/pshved/timeout). We limited each algorithm to 45 GB of RAM and 50 hours using a single processor.


***Data and code availability.*** The workflow utilized commands in GNU make (v.3.81), GNU bash (v.4.1.2), mothur (v.1.39.0) [@Schloss2009b], and R (v.`r paste(version$major, version$minor, sep='.')`) [@language2015]. Within R we utilized the wesanderson (v.`r packageDescription("wesanderson")$Version`) [@wesanderson], dplyr (v.`r packageDescription("dplyr")$Version`) [@dplyr], tidyr (v.`r packageDescription("tidyr")$Version`) [@tidyr], cowplot (v.`r packageDescription("cowplot")$Version`) [@cowplot], and ggplot2 (v.`r packageDescription("ggplot2")$Version`) [@ggplot2] packages. A reproducible version of this manuscript and analysis is available at https://github.com/SchlossLab/Westcott_OptiClust_mSphere_2017.



## Acknowledgements
This work was supported through funding from the National Institutes of Health to PDS (P30DK034933). SLW designed, implemented, and evaluated the algorithm. PDS designed and evaluated the algorithm. Both authors wrote and edited the manuscript.


\newpage


**Table 1. Description of datasets used to evaluate the OptiClust algorithm and compare its performance to other algorithms.** Each dataset contains sequences from the V4 region of the 16S rRNA gene. The number of distances for each dataset are those that were less than or equal to 0.03. The number of OTUs were determined using the OptiClust algorithm. The even and staggered datasets were generated by extracting the V4 region from full length reference sequences and the datasets from the natural communities were generated by sequencing the V4 region using a Illumina MiSeq with either paired 150 or 250 nt reads.

```{r results='asis', echo=FALSE, warning=FALSE, eval=TRUE}

dataset <- c(
							soil = "Soil",
							marine = "Marine",
							mice = "Mice",
							human = "Human",
							even = "Even",
							staggered = "Staggered"
						)

sequencing <- c(
							soil = "150",
							marine = "250",
							mice = "250",
							human = "250",
							even = "NA",
							staggered = "NA"
						)

reference <-  c(
							soil = "[@Johnston2016]",
							marine = "[@Henson2016]",
							mice = "[@Schloss2012]",
							human = "[@Baxter2016]",
							even = "[@Kopylova2016; @Schloss2016a]",
							staggered = "[@Kopylova2016; @Schloss2016a]"
						)

data_summary <- read.table(file="data/processed/datasets.summary", header=T, na.string="", stringsAsFactors=F)
data_summary <- data_summary[names(reference),]

stopifnot(names(dataset) == rownames(data_summary))
stopifnot(names(sequencing) == rownames(data_summary))
stopifnot(names(reference) == rownames(data_summary))

dataset_ref <- paste0(dataset, ' ', reference)

data_table <- cbind(dataset_ref, sequencing, data_summary$n_samples,
 										format(data_summary$n_total_seqs, big.mark=','),
 										format(data_summary$n_unique_seqs, big.mark=','),
										format(data_summary$n_distances, big.mark=','),
										format(round(data_summary$n_sobs), big.mark=','))

colnames(data_table) <- c("**Dataset (Ref.)**",
													"**Read Length**",
													"**Samples**",
													"**Total Seqs.**",
													"**Unique Seqs.**",
													"**Distances**",
													"**OTUs**")

kable(data_table, row.names=F, align="lcccccc")

```


\newpage

**Figure 1. Comparison of de novo clustering algorithms.**  Plot of MCC (A), number of OTUs (B), and execution times (C) for the comparison of *de novo* clustering algorithms when applied to four natural and two synthetic datasets. The first three columns of each figure contain the results of clustering the datasets (i) seeding the algorithm with one sequence per OTU and allowing the algorithm to proceed until the MCC value no longer changed; (ii) seeding the algorithm with one sequence per OTU and allowing the algorithm to proceed until the MCC changed by less than 0.0001; (iii) seeding the algorithm with all of the sequences in one OTU and allowing the algorithm to proceed until the MCC value no longer changed. The human dataset could not be clustered by the average neighbor, Sumaclust, USEARCH, or OTUCLUST with less than 45 GB of RAM or 50 hours of execution time. The median of 10 re-orderings of the data is presented for each method and dataset. The range of observed values is indicated by the error bars, which are typically smaller than the plotting symbol.

**Figure 2. OptiClust performance** The average execution time (A) and memory usage (B) required to cluster the four natural datasets. The confidence intervals indicate the range between the minimum and maximum values. The y-axis is scaled by the square root to demonstrate the relationship between the time and memory requirements relative to the number of unique sequences squared.

**Figure 3. Effects of taxonomically splitting the datasets on clustering quality.** The datasets were split at each taxonomic level based on their classification using a naive Bayesian classifier and clustered using average neighbor, VSEARCH-based DGC, and OptiClust.

\newpage

**Table S1. Summary of the average number of true positives, true negatives, false positives, false negatives and the resulting Matthews correlation coefficient for each of the clustering methods that were analyzed in this study for each of the six datasets.** Blank values indicate that those conditions could not be completed in 50 hours with 45 GB of RAM.

**Figure S1. The OptiClust algorithm is able to effectively cluster sequences into OTUs by minimizing or maximizing numerous metrics.** Plot of MCC (A), number of OTUs (B), and execution times (C) for the comparison of output from the OptiClust algorithm when to minimizing or maximizing a variety of parameters when applied to four natural and two synthetic datasets. Within mothur, OTU assignments can also be made using other metrics including minimizing false positives and maximizing the specificity, positive predictive value, and true negatives; however, these all resulted in sequences being assigned to separate OTUs, which resulted in no false positives and the maximum number of true negatives. The error bars indicate the range of values observed for 10 replicates.

**Figure S2. The OptiClust algorithm rapidly converges to optimize the Matthews correlation coefficient.** The six datasets were clustered into OTUs using the OptiClust algorithm seeking to maximize the Matthews correlation coefficient. This was repeated 10 times for each dataset.

**Supplemental text.** Worked example of how OptiClust algorithm clusters sequences into OTUs.

\newpage

## References
